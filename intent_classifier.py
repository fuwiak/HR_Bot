"""
–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∑–∞–ø–∏—Å—å
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ BERT –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
"""
import os
import logging
from typing import Dict, Tuple, Optional
import re

log = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    log.warning("‚ö†Ô∏è transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers torch")

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ sentence-transformers –¥–ª—è –ª–µ–≥–∫–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
_intent_model = None
_intent_tokenizer = None
_embedding_model_light = None

# –õ–µ–≥–∫–∞—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ –∏ –º–µ–Ω—å—à–µ)
LIGHT_EMBEDDING_MODEL = "cointegrated/rubert-tiny2"  # –û—á–µ–Ω—å –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:
# "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è, –ª–µ–≥–∫–∞—è
# "intfloat/multilingual-e5-small"  # –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è, —Å—Ä–µ–¥–Ω—è—è

def get_light_embedding_model():
    """–ü–æ–ª—É—á–∏—Ç—å –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    global _embedding_model_light
    
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        return None
    
    if _embedding_model_light is not None:
        return _embedding_model_light
    
    try:
        log.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {LIGHT_EMBEDDING_MODEL}...")
        _embedding_model_light = SentenceTransformer(LIGHT_EMBEDDING_MODEL)
        log.info("‚úÖ –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return _embedding_model_light
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏: {e}")
        return None

def classify_intent_with_embeddings(text: str, services: list, masters: list) -> Tuple[float, Dict]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (confidence_score, details)
    """
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        return 0.0, {"method": "fallback", "reason": "sentence-transformers –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}
    
    model = get_light_embedding_model()
    if not model:
        return 0.0, {"method": "fallback", "reason": "–º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        text_embedding = model.encode(text, normalize_embeddings=True)
        
        # –°–æ–∑–¥–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∑–∞–ø–∏—Å—å
        booking_examples = [
            "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è",
            "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —É—Å–ª—É–≥—É",
            "–Ω—É–∂–Ω–∞ –∑–∞–ø–∏—Å—å",
            "–∫–æ–≥–¥–∞ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è",
            "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è",
            "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∫ –º–∞—Å—Ç–µ—Ä—É",
            "–∑–∞–ø–∏—Å—å –Ω–∞ –∑–∞–≤—Ç—Ä–∞",
            "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∏–∂–∫—É",
            "–Ω—É–∂–Ω–∞ –∑–∞–ø–∏—Å—å –Ω–∞ –º–∞–Ω–∏–∫—é—Ä",
            "–∫–æ–≥–¥–∞ —Å–≤–æ–±–æ–¥–Ω–æ",
            "–º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è",
            "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –±—Ä–∏—Ç—å–µ",
            "–∑–∞–ø–∏—Å—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è",
            "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∑–∞–≤—Ç—Ä–∞ –≤ 8 —É—Ç—Ä–∞"
        ]
        
        booking_embeddings = model.encode(booking_examples, normalize_embeddings=True)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        import numpy as np
        similarities = np.dot(booking_embeddings, text_embedding)
        max_similarity = float(np.max(similarities))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —Å —É—Å–ª—É–≥–∞–º–∏
        if services:
            service_titles = [s.get("title", "") for s in services[:20]]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20
            service_embeddings = model.encode(service_titles, normalize_embeddings=True)
            service_similarities = np.dot(service_embeddings, text_embedding)
            max_service_similarity = float(np.max(service_similarities))
        else:
            max_service_similarity = 0.0
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        confidence = max(max_similarity, max_service_similarity * 0.8)
        
        details = {
            "method": "embedding",
            "booking_similarity": max_similarity,
            "service_similarity": max_service_similarity,
            "confidence": confidence
        }
        
        return confidence, details
        
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {e}")
        return 0.0, {"method": "error", "error": str(e)}

def classify_intent_hybrid(text: str, services: list, masters: list) -> Tuple[float, Dict]:
    """
    –ì–∏–±—Ä–∏–¥–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è:
    1. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
    2. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ fallback
    3. –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É—Å–ª—É–≥–∏, –º–∞—Å—Ç–µ—Ä–∞, –≤—Ä–µ–º—è)
    """
    text_lower = text.lower().strip()
    
    # 1. –ü–æ–ø—ã—Ç–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
    embedding_score, embedding_details = classify_intent_with_embeddings(text, services, masters)
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (fallback)
    keyword_score = 0.0
    booking_keywords = [
        "–∑–∞–ø–∏—Å—å", "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "–∑–∞–ø–∏—Å–∞—Ç—å", "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å",
        "–∫–æ–≥–¥–∞ –º–æ–∂–Ω–æ", "—Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è", "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ",
        "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞", "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "–Ω—É–∂–Ω–∞ –∑–∞–ø–∏—Å—å"
    ]
    
    for keyword in booking_keywords:
        if keyword in text_lower:
            keyword_score = 0.7
            break
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —É—Å–ª—É–≥
    service_score = 0.0
    if services:
        for service in services[:20]:
            service_title = service.get("title", "").lower()
            if service_title and service_title in text_lower:
                service_score = 0.6
                break
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
    time_score = 0.0
    time_markers = [
        "–∑–∞–≤—Ç—Ä–∞", "—Å–µ–≥–æ–¥–Ω—è", "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞", "–≤ ", "–Ω–∞ ", "—á–∞—Å–æ–≤", ":",
        "—É—Ç—Ä–∞", "—É—Ç—Ä–æ–º", "–≤–µ—á–µ—Ä–∞", "–≤–µ—á–µ—Ä–æ–º", "–¥–Ω—è", "–¥–Ω–µ–º"
    ]
    time_markers_found = sum(1 for marker in time_markers if marker in text_lower)
    if time_markers_found >= 2:
        time_score = 0.8
    elif time_markers_found >= 1:
        time_score = 0.5
    
    # 5. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏
    final_score = max(
        embedding_score * 0.5,  # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ - 50% –≤–µ—Å–∞
        keyword_score * 0.3,    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ - 30%
        service_score * 0.1,    # –£—Å–ª—É–≥–∏ - 10%
        time_score * 0.1        # –í—Ä–µ–º—è - 10%
    )
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º score
    indicators_count = sum([
        embedding_score > 0.5,
        keyword_score > 0,
        service_score > 0,
        time_score > 0
    ])
    
    if indicators_count >= 2:
        final_score = min(1.0, final_score * 1.2)
    
    details = {
        "method": "hybrid",
        "embedding": embedding_details,
        "keyword_score": keyword_score,
        "service_score": service_score,
        "time_score": time_score,
        "indicators_count": indicators_count,
        "final_score": final_score
    }
    
    return final_score, details

def classify_intent_with_llm(text: str, openrouter_api_key: str = None, openrouter_url: str = None) -> Tuple[float, Dict]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM (multi-agent –ø–æ–¥—Ö–æ–¥)
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenRouter API –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    if not openrouter_api_key:
        return 0.0, {"method": "llm", "reason": "OpenRouter API key –Ω–µ —É–∫–∞–∑–∞–Ω"}
    
    try:
        import requests
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        classification_prompt = f"""–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ —Å–∞–ª–æ–Ω–∞ –∫—Ä–∞—Å–æ—Ç—ã. –û–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–º –Ω–∞ –∑–∞–ø–∏—Å—å –∫ –º–∞—Å—Ç–µ—Ä—É.

–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{text}"

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ–º –æ—Ç 0.0 –¥–æ 1.0, –≥–¥–µ:
- 1.0 = —Ç–æ—á–Ω–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–ø–∏—Å—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "–∑–∞–ø–∏—Å—å –Ω–∞ –∑–∞–≤—Ç—Ä–∞", "–º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è")
- 0.5-0.9 = –≤–µ—Ä–æ—è—Ç–Ω–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–ø–∏—Å—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–∫–æ–≥–¥–∞ —Å–≤–æ–±–æ–¥–Ω–æ", "–Ω—É–∂–Ω–∞ —Å—Ç—Ä–∏–∂–∫–∞")
- 0.0-0.4 = –Ω–µ –∑–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–ø–∏—Å—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ø—Ä–∏–≤–µ—Ç", "–∫–∞–∫ –¥–µ–ª–∞", "—Å–ø–∞—Å–∏–±–æ")

–£—á–∏—Ç—ã–≤–∞–π –æ–ø–µ—á–∞—Ç–∫–∏ –∏ —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è. –ß–∏—Å–ª–æ:"""
        
        headers = {
            "Authorization": f"Bearer {openrouter_api_key}",
            "Content-Type": "application/json",
        }
        
        data = {
            "model": "x-ai/grok-4.1-fast:free",  # –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            "messages": [{"role": "user", "content": classification_prompt}],
            "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            "max_tokens": 10
        }
        
        response = requests.post(
            openrouter_url or "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=5
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("choices", [{}])[0].get("message", {}).get("content", "0.0").strip()
            
            # –ü–∞—Ä—Å–∏–º —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            import re
            numbers = re.findall(r'\d+\.?\d*', answer)
            if numbers:
                score = float(numbers[0])
                score = max(0.0, min(1.0, score))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0 –¥–æ 1
                return score, {"method": "llm", "score": score, "raw_answer": answer}
        
        return 0.0, {"method": "llm", "reason": f"–û—à–∏–±–∫–∞ API: {response.status_code}"}
        
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        return 0.0, {"method": "llm", "error": str(e)}

def is_booking_intent(text: str, services: list = None, masters: list = None, threshold: float = 0.5, 
                       use_llm: bool = False, openrouter_api_key: str = None, openrouter_url: str = None) -> Tuple[bool, Dict]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–æ–º –Ω–∞ –∑–∞–ø–∏—Å—å
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ LLM
    
    Args:
        text: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        services: –°–ø–∏—Å–æ–∫ —É—Å–ª—É–≥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        masters: –°–ø–∏—Å–æ–∫ –º–∞—Å—Ç–µ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.5)
        use_llm: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ LLM –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (multi-agent –ø–æ–¥—Ö–æ–¥)
        openrouter_api_key: API –∫–ª—é—á OpenRouter (–µ—Å–ª–∏ use_llm=True)
        openrouter_url: URL OpenRouter API (–µ—Å–ª–∏ use_llm=True)
    
    Returns:
        (is_booking, details) - —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å–æ–º –Ω–∞ –∑–∞–ø–∏—Å—å –∏ –¥–µ—Ç–∞–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    if not services:
        services = []
    if not masters:
        masters = []
    
    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω LLM, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
    if use_llm and openrouter_api_key:
        llm_score, llm_details = classify_intent_with_llm(text, openrouter_api_key, openrouter_url)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –º–µ—Ç–æ–¥–æ–º
        hybrid_score, hybrid_details = classify_intent_hybrid(text, services, masters)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: LLM 60%, –≥–∏–±—Ä–∏–¥–Ω—ã–π 40%
        final_score = llm_score * 0.6 + hybrid_score * 0.4
        
        details = {
            "method": "llm+hybrid",
            "llm_score": llm_score,
            "hybrid_score": hybrid_score,
            "final_score": final_score,
            "llm_details": llm_details,
            "hybrid_details": hybrid_details
        }
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≥–∏–±—Ä–∏–¥–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        final_score, details = classify_intent_hybrid(text, services, masters)
        details["final_score"] = final_score
    
    is_booking = final_score >= threshold
    
    log.info(f"üéØ INTENT CLASSIFICATION: '{text[:50]}...' -> score={final_score:.3f}, is_booking={is_booking}, method={details.get('method', 'unknown')}")
    
    return is_booking, details

# –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö
__all__ = [
    'is_booking_intent',
    'classify_intent_hybrid',
    'classify_intent_with_embeddings',
    'get_light_embedding_model',
    'TRANSFORMERS_AVAILABLE',
    'SENTENCE_TRANSFORMERS_AVAILABLE'
]

