"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""
import os
import asyncio
import logging
import tempfile
import uuid
from typing import Dict
from telegram import Update
from telegram.ext import ContextTypes
from qdrant_client.models import PointStruct

log = logging.getLogger(__name__)


async def extract_text_from_file(file_path: str, file_extension: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤"""
    try:
        if file_extension == 'pdf':
            # PDF
            from PyPDF2 import PdfReader
            reader = PdfReader(file_path)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n\n"
            return text
        
        elif file_extension in ['docx', 'doc']:
            # Word –¥–æ–∫—É–º–µ–Ω—Ç—ã
            try:
                import docx
                doc = docx.Document(file_path)
                text = "\n\n".join([para.text for para in doc.paragraphs])
                return text
            except ImportError:
                log.error("‚ùå python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
                return ""
        
        elif file_extension in ['xlsx', 'xls']:
            # Excel
            import pandas as pd
            df = pd.read_excel(file_path, sheet_name=None)  # –ß–∏—Ç–∞–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã
            text = ""
            for sheet_name, sheet_df in df.items():
                text += f"=== –õ–∏—Å—Ç: {sheet_name} ===\n\n"
                text += sheet_df.to_string(index=False) + "\n\n"
            return text
        
        elif file_extension == 'txt':
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        else:
            return ""
    
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ {file_path}: {e}")
        return ""


async def upload_to_qdrant(text_content: str, file_name: str, user_id: int, username: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Qdrant —Å —á–∞–Ω–∫–∏–Ω–≥–æ–º"""
    try:
        from services.rag.qdrant_loader import QdrantLoader
        from services.rag.qdrant_helper import generate_embedding_async
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_id = str(uuid.uuid4())
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º QdrantLoader
        loader = QdrantLoader()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
        try:
            from langchain_text_splitters import RecursiveCharacterTextSplitter
        except ImportError:
            from text_splitter import RecursiveCharacterTextSplitter
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        chunks = text_splitter.split_text(text_content)
        log.info(f"üìÑ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_name}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        documents = []
        for i, chunk in enumerate(chunks):
            if len(chunk.strip()) < 10:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏
                continue
            
            doc = {
                "id": f"{doc_id}_chunk_{i}",
                "text": chunk,
                "metadata": {
                    "source": file_name,
                    "doc_id": doc_id,
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "uploaded_by": username,
                    "user_id": user_id,
                    "category": "user_upload",
                    "title": file_name
                }
            }
            documents.append(doc)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Qdrant —á–µ—Ä–µ–∑ loader
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫–∏ –±–∞—Ç—á–∞–º–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        points = []
        batch_size = 10  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 10 —á–∞–Ω–∫–æ–≤ –∑–∞ —Ä–∞–∑
        
        for batch_start in range(0, len(documents), batch_size):
            batch_end = min(batch_start + batch_size, len(documents))
            batch_docs = documents[batch_start:batch_end]
            
            log.info(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞–Ω–∫–∏ {batch_start + 1}-{batch_end} –∏–∑ {len(documents)}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞
            batch_tasks = []
            for doc in batch_docs:
                batch_tasks.append(generate_embedding_async(doc["text"]))
            
            # –ñ–¥–µ–º –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            batch_embeddings = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫–∏ –¥–ª—è –±–∞—Ç—á–∞
            for doc, embedding in zip(batch_docs, batch_embeddings):
                if isinstance(embedding, Exception) or embedding is None:
                    log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞–Ω–∫–∞ {doc['id']}")
                    continue
                
                # –°–æ–∑–¥–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ hash —Å—Ç—Ä–æ–∫–∏
                point_id = abs(hash(doc["id"])) % (10 ** 10)
                
                point = PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload={
                        "text": doc["text"],
                        "source": doc["metadata"]["source"],
                        "doc_id": doc["metadata"]["doc_id"],
                        "chunk_index": doc["metadata"]["chunk_index"],
                        "uploaded_by": doc["metadata"]["uploaded_by"],
                        "user_id": doc["metadata"]["user_id"],
                        "category": doc["metadata"]["category"],
                        "title": doc["metadata"]["title"],
                        "chunk_id": doc["id"]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–π ID –≤ payload
                    }
                )
                points.append(point)
            
            log.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batch_embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –±–∞—Ç—á–µ")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Qdrant
        if points:
            loader.client.upsert(
                collection_name=loader.collection_name,
                points=points
            )
            log.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(points)} —á–∞–Ω–∫–æ–≤ –≤ Qdrant")
            
            return {
                "success": True,
                "chunks_count": len(points),
                "doc_id": doc_id
            }
        else:
            return {
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            }
    
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Qdrant: {e}")
        import traceback
        log.error(f"‚ùå Traceback: {traceback.format_exc()}")
        return {
            "success": False,
            "error": str(e)
        }


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ Telegram"""
    try:
        document = update.message.document
        user_id = update.message.from_user.id
        username = update.message.from_user.username or "unknown"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å 20MB)
        if document.file_size > 20 * 1024 * 1024:
            await update.message.reply_text(
                "‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 20 –ú–ë"
            )
            return
        
        file_name = document.file_name
        file_extension = file_name.split('.')[-1].lower() if '.' in file_name else ''
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
        supported_formats = ['pdf', 'docx', 'doc', 'xlsx', 'xls', 'txt']
        if file_extension not in supported_formats:
            await update.message.reply_text(
                f"‚ùå –§–æ—Ä–º–∞—Ç `.{file_extension}` –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.\n\n"
                f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(supported_formats)}",
                parse_mode='Markdown'
            )
            return
        
        log.info(f"üì§ –ü–æ–ª—É—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {username} (ID: {user_id}): {file_name}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å (–±–µ–∑ Markdown –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Ñ–∞–π–ª–æ–≤)
        status_msg = await update.message.reply_text(
            f"‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç: {file_name}\n"
            f"–†–∞–∑–º–µ—Ä: {document.file_size / 1024:.1f} –ö–ë"
        )
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file = await context.bot.get_file(document.file_id)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        temp_dir = tempfile.mkdtemp()
        file_path = os.path.join(temp_dir, file_name)
        
        await file.download_to_drive(file_path)
        log.info(f"‚úÖ –§–∞–π–ª —Å–∫–∞—á–∞–Ω: {file_path}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        await status_msg.edit_text(
            f"‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–æ–∫—É–º–µ–Ω—Ç: {file_name}\n"
            f"–ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç –∏ —Å–æ–∑–¥–∞—é —á–∞–Ω–∫–∏..."
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        text_content = await extract_text_from_file(file_path, file_extension)
        
        if not text_content or len(text_content.strip()) < 50:
            await status_msg.edit_text(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ `{file_name}`.\n"
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç.",
                parse_mode='Markdown'
            )
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.remove(file_path)
                os.rmdir(temp_dir)
            except:
                pass
            return
        
        log.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {file_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Qdrant
        await status_msg.edit_text(
            f"‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...\n"
            f"–ò–Ω–¥–µ–∫—Å–∏—Ä—É—é —á–∞–Ω–∫–∏ –≤ Qdrant..."
        )
        
        result = await upload_to_qdrant(
            text_content=text_content,
            file_name=file_name,
            user_id=user_id,
            username=username
        )
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            os.remove(file_path)
            os.rmdir(temp_dir)
        except Exception as e:
            log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")
        
        if result['success']:
            await status_msg.edit_text(
                f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π!\n\n"
                f"üìÑ –§–∞–π–ª: {file_name}\n"
                f"üìä –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {result['chunks_count']}\n"
                f"üÜî ID –¥–æ–∫—É–º–µ–Ω—Ç–∞: {result['doc_id']}\n\n"
                f"–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ —ç—Ç–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É:\n"
                f"‚Ä¢ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –≤ —á–∞—Ç–µ\n"
                f"‚Ä¢ –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /rag_search [–∑–∞–ø—Ä–æ—Å]"
            )
            log.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {file_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: {result['doc_id']})")
        else:
            await status_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{result['error']}"
            )
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_name}: {result['error']}")
            
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        import traceback
        log.error(f"‚ùå Traceback: {traceback.format_exc()}")
        await update.message.reply_text(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{str(e)}"
        )


__all__ = ['handle_document']
