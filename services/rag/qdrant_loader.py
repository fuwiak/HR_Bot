"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —á–∞–Ω–∫–∏–Ω–≥, –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ whitelist.
"""

import os
import logging
import asyncio
import hashlib
from typing import List, Dict, Any, Optional, Set
from pathlib import Path
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance, VectorParams, PointStruct,
    CollectionStatus, Filter, FieldCondition, MatchValue
)
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–≥–∫—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é text splitter –±–µ–∑ langchain
try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except ImportError:
    # Fallback –Ω–∞ –ª–µ–≥–∫—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    try:
        from services.helpers.text_splitter import RecursiveCharacterTextSplitter
    except ImportError:
        # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Ç—å
        import sys
        from pathlib import Path
        project_root = Path(__file__).parent.parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))
        from services.helpers.text_splitter import RecursiveCharacterTextSplitter
# –ò—Å–ø–æ–ª—å–∑—É–µ–º API —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ qdrant_helper (OpenAI text-embedding-3-small)
# from langchain_huggingface import HuggingFaceEmbeddings
import uuid
import re
from collections import defaultdict

from whitelist import WhitelistManager

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
try:
    from dotenv import load_dotenv
    project_root = Path(__file__).parent.parent.parent
    load_dotenv(project_root / ".env")
except ImportError:
    pass  # python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

logger = logging.getLogger(__name__)

try:
    from rank_bm25 import BM25Okapi
    BM25_AVAILABLE = True
except ImportError:
    BM25_AVAILABLE = False
    logger.warning("rank-bm25 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. BM25 –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install rank-bm25")


class QdrantLoader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –≤ Qdrant (Singleton)"""
    
    _instance: Optional['QdrantLoader'] = None
    _lock = None
    
    def __new__(
        cls,
        collection_name: str = "hr2137_bot_knowledge_base",
        qdrant_url: Optional[str] = None,
        qdrant_api_key: Optional[str] = None,
        chunk_size: int = 500,
        chunk_overlap: int = 50,
        embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        force_new: bool = False
    ):
        """
        Singleton –ø–∞—Ç—Ç–µ—Ä–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π.
        
        Args:
            force_new: –ï—Å–ª–∏ True, —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        """
        if cls._instance is None or force_new:
            if cls._lock is None:
                import threading
                cls._lock = threading.Lock()
            
            with cls._lock:
                if cls._instance is None or force_new:
                    instance = super(QdrantLoader, cls).__new__(cls)
                    instance._initialized = False
                    if not force_new:
                        cls._instance = instance
                    return instance
        return cls._instance
    
    def __init__(
        self,
        collection_name: str = "hr2137_bot_knowledge_base",
        qdrant_url: Optional[str] = None,
        qdrant_api_key: Optional[str] = None,
        chunk_size: int = 500,
        chunk_overlap: int = 50,
        embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        force_new: bool = False
    ):
        # –ï—Å–ª–∏ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω - –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–Ω–æ–≤–∞
        if hasattr(self, '_initialized') and self._initialized:
            return
        self.collection_name = collection_name
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL Qdrant (—Ç–∞ –∂–µ –ª–æ–≥–∏–∫–∞, —á—Ç–æ –≤ qdrant_helper.py)
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 1) QDRANT_HOST, 2) RAILWAY_SERVICE_QDRANT_URL, 3) –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π qdrant_url, 4) QDRANT_URL, 5) private domain, 6) localhost
        qdrant_host = os.getenv("QDRANT_HOST")
        if qdrant_host:
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: QDRANT_HOST –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–º–µ–Ω –ø—É–±–ª–∏—á–Ω—ã–º (Railway public domain)
                is_public_domain = (
                    ".up.railway.app" in qdrant_host or
                    ".railway.app" in qdrant_host or
                    qdrant_host.startswith("https://")
                )
                
                if is_public_domain:
                    # –ü—É–±–ª–∏—á–Ω—ã–π –¥–æ–º–µ–Ω Railway - –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTPS –±–µ–∑ –ø–æ—Ä—Ç–∞
                    if qdrant_host.startswith("https://"):
                        self.qdrant_url = qdrant_host
                    elif qdrant_host.startswith("http://"):
                        self.qdrant_url = qdrant_host.replace("http://", "https://")
                    else:
                        self.qdrant_url = f"https://{qdrant_host}"
                    logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–π Railway Qdrant: {self.qdrant_url}")
                else:
                    # –ü—Ä–∏–≤–∞—Ç–Ω—ã–π –¥–æ–º–µ–Ω Railway - –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTP —Å –ø–æ—Ä—Ç–æ–º
                    qdrant_port = os.getenv("QDRANT_PORT", "6333")
                    self.qdrant_url = f"http://{qdrant_host}:{qdrant_port}"
                    logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏–≤–∞—Ç–Ω—ã–π Railway Qdrant: {self.qdrant_url}")
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: RAILWAY_SERVICE_QDRANT_URL (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è Railway, –µ—Å–ª–∏ QDRANT_HOST –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        elif railway_service_qdrant_url := os.getenv("RAILWAY_SERVICE_QDRANT_URL"):
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è Railway
            if railway_service_qdrant_url.startswith("https://"):
                self.qdrant_url = railway_service_qdrant_url
            else:
                self.qdrant_url = f"https://{railway_service_qdrant_url}"
            logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Railway Qdrant –∏–∑ RAILWAY_SERVICE_QDRANT_URL: {self.qdrant_url}")
        elif os.getenv("RAILWAY_ENVIRONMENT") or os.getenv("RAILWAY_PROJECT_ID"):
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –í Railway, –Ω–æ QDRANT_HOST –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –ø—Ä–æ–±—É–µ–º private domain
                qdrant_port = os.getenv("QDRANT_PORT", "6333")
                self.qdrant_url = f"http://qdrant.railway.internal:{qdrant_port}"
                logger.info(f"‚ö†Ô∏è QDRANT_HOST –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É–µ–º Railway private domain: {self.qdrant_url}")
        else:
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4: –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
                self.qdrant_url = qdrant_url or os.getenv("QDRANT_URL", "http://localhost:6333")
                if self.qdrant_url == "http://localhost:6333":
                    logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π Qdrant: {self.qdrant_url}")
                else:
                    logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Qdrant URL: {self.qdrant_url}")
        
        # API –∫–ª—é—á –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è Railway Qdrant
        self.qdrant_api_key = qdrant_api_key or os.getenv("QDRANT_API_KEY", "")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç Qdrant
        is_public = self.qdrant_url.startswith("https://")
        timeout_seconds = 30.0 if is_public else 10.0
        
        client_kwargs = {"url": self.qdrant_url, "timeout": timeout_seconds}
        # API –∫–ª—é—á –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö Qdrant Cloud –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        if self.qdrant_api_key and not qdrant_host:
            client_kwargs["api_key"] = self.qdrant_api_key
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Qdrant Cloud —Å API –∫–ª—é—á–æ–º: {self.qdrant_url}")
        
        self.client = QdrantClient(**client_kwargs)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embeddings —á–µ—Ä–µ–∑ API (–∫–∞–∫ –≤ qdrant_helper)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é, –∫–∞–∫ –≤ Telegram –±–æ—Ç–µ
        try:
            from services.rag.qdrant_helper import generate_embedding_async, EMBEDDING_DIMENSION
            self._qdrant_embedding_async = generate_embedding_async
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            self.embedding_dim = EMBEDDING_DIMENSION
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è API –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.embedding_dim})")
        except ImportError:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ qdrant_helper")
            self.embedding_dim = 1536
            self._qdrant_embedding_async = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        
        # Whitelist –º–µ–Ω–µ–¥–∂–µ—Ä
        self.whitelist = WhitelistManager()
        
        # BM25 –∏–Ω–¥–µ–∫—Å (–±—É–¥–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
        self.bm25_index: Optional[BM25Okapi] = None
        self.bm25_documents: List[List[str]] = []  # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è BM25
        self.bm25_doc_map: Dict[int, Dict[str, Any]] = {}  # –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–∞ BM25 –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º Qdrant
        
        # –§–ª–∞–≥ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏—è BM25 –∏–Ω–¥–µ–∫—Å–∞
        self._bm25_needs_rebuild = True
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self._ensure_collection()
        
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (–¥–ª—è singleton)
        self._initialized = True
    
    def _ensure_collection(self) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        try:
            collections = self.client.get_collections().collections
            collection_names = [c.name for c in collections]
            
            if self.collection_name not in collection_names:
                logger.info(f"Creating collection: {self.collection_name}")
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=self.embedding_dim,
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"Collection {self.collection_name} created")
            else:
                logger.info(f"Collection {self.collection_name} already exists")
                
        except Exception as e:
            logger.error(f"Error ensuring collection: {str(e)}")
            raise
    
    def load_document(
        self,
        text: str,
        metadata: Dict[str, Any],
        filter_by_whitelist: bool = True
    ) -> int:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ Qdrant.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å source_url)
            filter_by_whitelist: –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ whitelist
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        """
        source_url = metadata.get("source_url") or metadata.get("url", "")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ whitelist
        if filter_by_whitelist and not self.whitelist.is_allowed(source_url):
            logger.warning(f"Document filtered by whitelist: {source_url}")
            return 0
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        chunks = self.text_splitter.split_text(text)
        logger.info(f"Split document into {len(chunks)} chunks")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings —á–µ—Ä–µ–∑ API (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –∫–∞–∫ –≤ Telegram –±–æ—Ç–µ)
        if self._qdrant_embedding_async is None:
            logger.error("Embedding —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞")
            return 0
        
        embeddings_data = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–∫–∞–∫ –≤ Telegram –±–æ—Ç–µ)
        async def generate_all_embeddings():
            tasks = [self._qdrant_embedding_async(chunk) for chunk in chunks]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            return results
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–Ω—ã–π event loop
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # –ï—Å–ª–∏ loop —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –≤ –ø–æ—Ç–æ–∫–µ
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, generate_all_embeddings())
                        embeddings_results = future.result(timeout=300)  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                else:
                    embeddings_results = loop.run_until_complete(generate_all_embeddings())
            except RuntimeError:
                # –ù–µ—Ç event loop, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
                embeddings_results = asyncio.run(generate_all_embeddings())
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for i, (chunk, embedding_result) in enumerate(zip(chunks, embeddings_results)):
                if isinstance(embedding_result, Exception):
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞–Ω–∫–∞ {i}: {embedding_result}")
                elif embedding_result:
                    embeddings_data.append((i, chunk, embedding_result))
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞–Ω–∫–∞ {i}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return 0
        
        if not embeddings_data:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞")
            return 0
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        points = []
        for orig_idx, chunk, embedding in embeddings_data:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à –æ—Ç —Ç–µ–∫—Å—Ç–∞ —á–∞–Ω–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ ID
            point_id_str = f"{source_url}_{i}_{hashlib.md5(chunk.encode()).hexdigest()}"
            point_id = int(hashlib.md5(point_id_str.encode()).hexdigest()[:8], 16)
            point_metadata = {
                **metadata,
                "chunk_index": orig_idx,
                "text": chunk,
                "source_url": source_url
            }
            
            points.append(
                PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload=point_metadata
                )
            )
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ Qdrant
        try:
            self.client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            logger.info(f"Inserted {len(points)} points into {self.collection_name}")
            
            # –ü–æ–º–µ—á–∞–µ–º BM25 –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏—è
            self._bm25_needs_rebuild = True
            
            return len(points)
        except Exception as e:
            logger.error(f"Error inserting points: {str(e)}")
            raise
    
    def load_from_file(
        self,
        file_path: str,
        source_url: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> int:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ —Ñ–∞–π–ª–∞.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏ PDF.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            source_url: URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        """
        file_path = Path(file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        file_ext = file_path.suffix.lower()
        
        if file_ext == '.pdf':
            # –ß–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª
            try:
                import PyPDF2
            except ImportError:
                raise ImportError("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install PyPDF2")
            
            text = ""
            try:
                with open(file_path, "rb") as f:
                    pdf_reader = PyPDF2.PdfReader(f)
                    for page_num, page in enumerate(pdf_reader.pages):
                        try:
                            page_text = page.extract_text()
                            if page_text:
                                text += f"\n\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ---\n\n"
                                text += page_text
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF —Ñ–∞–π–ª–∞: {str(e)}")
                raise
        else:
            # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    text = f.read()
            except UnicodeDecodeError:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for encoding in ['cp1251', 'latin-1', 'iso-8859-1']:
                    try:
                        with open(file_path, "r", encoding=encoding) as f:
                            text = f.read()
                            break
                    except (UnicodeDecodeError, LookupError):
                        continue
                else:
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª {file_path} —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏")
        
        if not text.strip():
            logger.warning(f"–§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
            return 0
        
        doc_metadata = {
            "source_url": source_url,
            "file_name": file_path.name,
            "file_type": file_ext,
            **(metadata or {})
        }
        
        return self.load_document(text, doc_metadata)
    
    def _tokenize(self, text: str) -> List[str]:
        """–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è BM25 (—Ä—É—Å—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)"""
        text_lower = text.lower()
        words = re.findall(r'\b\w+\b', text_lower)
        return words
    
    def _build_bm25_index(self) -> None:
        """–°—Ç—Ä–æ–∏—Ç BM25 –∏–Ω–¥–µ–∫—Å –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant"""
        if not BM25_AVAILABLE:
            return
        
        try:
            logger.info("Building BM25 index from Qdrant documents...")
            scroll_result = self.client.scroll(
                collection_name=self.collection_name,
                limit=10000,
                with_payload=True,
                with_vectors=False
            )
            points = scroll_result[0]
            
            if not points:
                return
            
            self.bm25_documents = []
            self.bm25_doc_map = {}
            
            for idx, point in enumerate(points):
                text = point.payload.get("text", "")
                if not text:
                    continue
                tokens = self._tokenize(text)
                if tokens:
                    self.bm25_documents.append(tokens)
                    self.bm25_doc_map[idx] = {
                        "text": text,
                        "source_url": point.payload.get("source_url", ""),
                        "payload": point.payload
                    }
            
            if self.bm25_documents:
                self.bm25_index = BM25Okapi(self.bm25_documents)
                logger.info(f"BM25 index built with {len(self.bm25_documents)} documents")
                
        except Exception as e:
            logger.error(f"Error building BM25 index: {str(e)}")
            self.bm25_index = None
    
    def _bm25_search(self, query: str, top_k: int = 5, filter_by_whitelist: bool = True) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç BM25 –ø–æ–∏—Å–∫"""
        if not BM25_AVAILABLE:
            return []
        
        if self._bm25_needs_rebuild or not self.bm25_index:
            self._build_bm25_index()
            self._bm25_needs_rebuild = False
        
        if not self.bm25_index:
            return []
        
        query_tokens = self._tokenize(query)
        if not query_tokens:
            return []
        
        scores = self.bm25_index.get_scores(query_tokens)
        top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k * 2]
        
        documents = []
        for idx in top_indices:
            if scores[idx] <= 0:
                continue
            doc_data = self.bm25_doc_map.get(idx)
            if not doc_data:
                continue
            
            if filter_by_whitelist:
                source_url = doc_data.get("source_url", "")
                if not self.whitelist.is_allowed(source_url):
                    continue
            
            import math
            normalized_score = 1 / (1 + math.exp(-scores[idx] / 10)) if scores[idx] > 0 else 0
            
            doc = {
                "text": doc_data.get("text", ""),
                "source_url": doc_data.get("source_url", ""),
                "score": normalized_score,
                "bm25_raw_score": float(scores[idx]),
                "search_method": "bm25",
                **{k: v for k, v in doc_data.get("payload", {}).items() 
                   if k not in ["text", "source_url"]}
            }
            documents.append(doc)
        
        return documents[:top_k]
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        score_threshold: float = 0.7,
        filter_by_whitelist: bool = True,
        search_strategy: str = "hybrid",
        dense_weight: float = 0.4,
        bm25_weight: float = 0.6
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π BM25 –∏ hybrid search.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            score_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score
            filter_by_whitelist: –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ whitelist
            search_strategy: "dense", "bm25", –∏–ª–∏ "hybrid"
            dense_weight: –í–µ—Å –¥–ª—è dense search (–¥–ª—è hybrid)
            bm25_weight: –í–µ—Å –¥–ª—è BM25 search (–¥–ª—è hybrid)
        """
        if search_strategy == "bm25":
            return self._bm25_search(query, top_k, filter_by_whitelist)
        
        # Dense search - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        if self._qdrant_embedding_async is None:
            logger.error("Embedding —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞")
            return []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        try:
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, self._qdrant_embedding_async(query))
                        query_embedding = future.result(timeout=30)
                else:
                    query_embedding = loop.run_until_complete(self._qdrant_embedding_async(query))
            except RuntimeError:
                query_embedding = asyncio.run(self._qdrant_embedding_async(query))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return []
        if not query_embedding:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞")
            return []
        search_filter = None
        if filter_by_whitelist:
            allowed_urls = self.whitelist.get_allowed_urls()
            if allowed_urls:
                conditions = [FieldCondition(key="source_url", match=MatchValue(value=url)) for url in allowed_urls]
                if conditions:
                    search_filter = Filter(must=[conditions[0]])
        
        dense_results = []
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º query_points –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å in-memory –∏ remote Qdrant
            # –î–ª—è in-memory –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä –Ω–∞–ø—Ä—è–º—É—é
            try:
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä (—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è in-memory –∏ –º–Ω–æ–≥–∏—Ö –≤–µ—Ä—Å–∏–π remote)
                query_points = self.client.query_points(
                    collection_name=self.collection_name,
                    query=query_embedding,  # –ü—Ä–æ—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä
                    limit=top_k * 2 if search_strategy == "hybrid" else top_k,
                    score_threshold=score_threshold
                )
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ whitelist –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                for point in query_points.points:
                    if point.score < score_threshold:
                        continue
                    
                    source_url = point.payload.get("source_url", "")
                    if filter_by_whitelist and not self.whitelist.is_allowed(source_url):
                        continue
                    
                    doc = {
                        "text": point.payload.get("text", ""),
                        "source_url": source_url,
                        "score": point.score,
                        "search_method": "dense",
                        **{k: v for k, v in point.payload.items() if k not in ["text", "source_url"]}
                    }
                    dense_results.append(doc)
                    
            except (TypeError, AttributeError, ValueError) as e:
                # –ï—Å–ª–∏ –ø—Ä—è–º–æ–π –≤–µ–∫—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
                logger.error(f"Error in dense search with direct vector: {str(e)}")
                logger.warning("Falling back to empty results. Check Qdrant client configuration.")
                dense_results = []
        
        except Exception as e:
            logger.error(f"Error in dense search: {str(e)}")
        
        if filter_by_whitelist:
            dense_results = self.whitelist.filter_sources(dense_results)
        
        if search_strategy == "dense":
            return dense_results[:top_k]
        
        if search_strategy == "hybrid":
            return self._hybrid_search(query, dense_results, top_k, score_threshold, filter_by_whitelist, dense_weight, bm25_weight)
        
        return dense_results[:top_k]
    
    def _hybrid_search(
        self, query: str, dense_results: List[Dict[str, Any]], top_k: int,
        score_threshold: float, filter_by_whitelist: bool, dense_weight: float, bm25_weight: float
    ) -> List[Dict[str, Any]]:
        """–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25 –∏ Dense search"""
        bm25_results = self._bm25_search(query, top_k * 2, filter_by_whitelist)
        
        if not bm25_results:
            return dense_results[:top_k]
        
        def normalize_scores(results):
            if not results:
                return []
            scores = [r["score"] for r in results]
            max_score, min_score = max(scores) if scores else 1.0, min(scores) if scores else 0.0
            score_range = max_score - min_score if max_score != min_score else 1.0
            for r in results:
                r["normalized_score"] = (r["score"] - min_score) / score_range if score_range > 0 else 0.5
            return results
        
        dense_norm = normalize_scores(dense_results.copy())
        bm25_norm = normalize_scores(bm25_results.copy())
        combined_scores = {}
        
        for doc in dense_norm:
            text_key = doc["text"][:200]
            combined_scores[text_key] = {**doc, "hybrid_score": doc["normalized_score"] * dense_weight, "dense_score": doc["normalized_score"], "bm25_score": 0.0}
        
        for doc in bm25_norm:
            text_key = doc["text"][:200]
            bm25_norm_score = doc["normalized_score"]
            if text_key in combined_scores:
                combined_scores[text_key]["hybrid_score"] += bm25_norm_score * bm25_weight
                combined_scores[text_key]["bm25_score"] = bm25_norm_score
            else:
                combined_scores[text_key] = {**doc, "hybrid_score": bm25_norm_score * bm25_weight, "dense_score": 0.0, "bm25_score": bm25_norm_score}
        
        combined_list = sorted(combined_scores.values(), key=lambda x: x["hybrid_score"], reverse=True)
        filtered = [doc for doc in combined_list if doc["hybrid_score"] >= score_threshold]
        
        for doc in filtered:
            doc["score"] = doc["hybrid_score"]
            doc["search_method"] = "hybrid"
        
        return filtered[:top_k]
    
    def delete_collection(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        try:
            self.client.delete_collection(self.collection_name)
            logger.info(f"Collection {self.collection_name} deleted")
        except Exception as e:
            logger.error(f"Error deleting collection: {str(e)}")
    
    def get_collection_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            info = self.client.get_collection(self.collection_name)
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã CollectionInfo
            result = {
                "name": self.collection_name,
                "points_count": getattr(info, 'points_count', 0),
                "status": str(getattr(info, 'status', 'unknown'))
            }
            
            # vectors_count –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö
            if hasattr(info, 'vectors_count'):
                result["vectors_count"] = info.vectors_count
            else:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–≤–Ω—è–µ—Ç—Å—è points_count –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
                result["vectors_count"] = result["points_count"]
            
            return result
        except Exception as e:
            logger.error(f"Error getting collection info: {str(e)}")
            return {
                "name": self.collection_name,
                "points_count": 0,
                "vectors_count": 0,
                "status": "error"
            }

