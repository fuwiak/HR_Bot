"""
LangGraph Conversation Workflow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ —Å –∏—Å—Ç–æ—Ä–∏–µ–π —Å–æ–æ–±—â–µ–Ω–∏–π
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ HR –±–æ—Ç–∞ —Å –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é
"""
import os
import sys
import logging
from typing import Dict, Any, Optional, List, TypedDict
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))

try:
    from langgraph.graph import StateGraph, END, START
    from langgraph.graph.message import add_messages
    from typing import Annotated
    try:
        from langchain_core.messages import HumanMessage, AIMessage
        LANGCHAIN_MESSAGES_AVAILABLE = True
    except ImportError:
        LANGCHAIN_MESSAGES_AVAILABLE = False
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    LANGCHAIN_MESSAGES_AVAILABLE = False
    add_messages = None
    Annotated = None

log = logging.getLogger(__name__)


class ConversationState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è LangGraph conversation workflow —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π add_messages"""
    messages: Annotated[list, add_messages] if add_messages else List[Dict[str, str]]
    current_message: str
    system_prompt: str
    task_type: str  # pricing, general, booking, service_info
    response: Optional[str]
    error: Optional[str]
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_name: Optional[str]
    user_id: Optional[str]
    platform: Optional[str]
    bot_already_introduced: Optional[bool]
    needs_user_name: Optional[bool]
    # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
    rag_context: Optional[str]
    search_results: Optional[list]
    pricing_info: Optional[dict]


class LangGraphConversationWorkflow:
    """
    LangGraph workflow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ HR –±–æ—Ç–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ user_id
    """
    
    def __init__(self, max_history_messages: int = 50):
        self.graph = None
        self._initialized = False
        self._thread_states: Dict[str, Dict[str, Any]] = {}
        self.max_history_messages = max_history_messages
    
    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LangGraph workflow"""
        if not LANGGRAPH_AVAILABLE:
            log.warning("LangGraph –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, workflow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
        
        if self._initialized:
            return True
        
        try:
            workflow = StateGraph(ConversationState)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã
            workflow.add_node("trim_history", self._trim_history_node)
            workflow.add_node("classify_query", self._classify_query_node)
            workflow.add_node("search_rag", self._search_rag_node)
            workflow.add_node("format_messages", self._format_messages_node)
            workflow.add_node("generate_response", self._generate_response_node)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ç–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            workflow.set_entry_point("trim_history")
            workflow.add_edge("trim_history", "classify_query")
            workflow.add_edge("classify_query", "search_rag")
            workflow.add_edge("search_rag", "format_messages")
            workflow.add_edge("format_messages", "generate_response")
            workflow.add_edge("generate_response", END)
            
            self.graph = workflow.compile()
            self._initialized = True
            log.info("‚úÖ LangGraph Conversation Workflow –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return True
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LangGraph: {e}", exc_info=True)
            return False
    
    async def _trim_history_node(self, state: ConversationState) -> Dict[str, Any]:
        """–û–±—Ä–µ–∑–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–æ–æ–±—â–µ–Ω–∏–π"""
        try:
            user_id = state.get("user_id")
            platform = state.get("platform", "telegram")
            msgs = state.get("messages", [])
            
            if user_id:
                thread_key = f"{user_id}_{platform}"
                prev_state = self._thread_states.get(thread_key, {})
                prev_messages = prev_state.get("messages", [])
                
                if prev_messages:
                    if isinstance(prev_messages[0], dict):
                        if LANGCHAIN_MESSAGES_AVAILABLE:
                            converted = []
                            for msg in prev_messages:
                                role = msg.get("role", "user")
                                content = msg.get("content", "")
                                if role == "user":
                                    converted.append(HumanMessage(content=content))
                                elif role == "assistant":
                                    converted.append(AIMessage(content=content))
                            prev_messages = converted
                    msgs = list(prev_messages) + msgs
                
                msgs = msgs[-self.max_history_messages:] if len(msgs) > self.max_history_messages else msgs
                self._thread_states[thread_key] = {"messages": msgs}
                state["messages"] = msgs
                log.debug(f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è –æ–±—Ä–µ–∑–∞–Ω–∞ –¥–æ {len(msgs)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            else:
                msgs = msgs[-self.max_history_messages:] if len(msgs) > self.max_history_messages else msgs
                state["messages"] = msgs
            
            return state
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–µ–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return state
    
    async def _classify_query_node(self, state: ConversationState) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            current_message = state.get("current_message", "").lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
            pricing_keywords = ["—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Å—Ç–æ–∏—Ç", "—Ä—É–±–ª–µ–π", "—Ä—É–±", "–ø—Ä–∞–π—Å", 
                               "—Å–∫–æ–ª—å–∫–æ", "–∫—É–ø–∏—Ç—å", "—Ä–∞—Å—Ü–µ–Ω–∫–∏", "—Ç–∞—Ä–∏—Ñ—ã", "–æ—Ç 90"]
            booking_keywords = ["–∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "–∑–∞–ø–∏—Å—å", "–±—Ä–æ–Ω—å", "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", 
                               "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "–Ω–∞–∑–Ω–∞—á–∏—Ç—å"]
            service_keywords = ["—É—Å–ª—É–≥–∞", "—É—Å–ª—É–≥–∏", "—á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ", "—á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç–µ",
                               "—Ñ–æ—Ä—Å–∞–π—Ç", "–∫–æ—É—á–∏–Ω–≥", "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"]
            
            if any(kw in current_message for kw in pricing_keywords):
                state["task_type"] = "pricing"
            elif any(kw in current_message for kw in booking_keywords):
                state["task_type"] = "booking"
            elif any(kw in current_message for kw in service_keywords):
                state["task_type"] = "service_info"
            else:
                state["task_type"] = "general"
            
            log.info(f"üìä –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {state['task_type']}")
            return state
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            state["task_type"] = "general"
            return state
    
    async def _search_rag_node(self, state: ConversationState) -> Dict[str, Any]:
        """–ü–æ–∏—Å–∫ –≤ RAG –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        try:
            current_message = state.get("current_message", "")
            task_type = state.get("task_type", "general")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º qdrant_helper
            try:
                from qdrant_helper import search_service
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                limit = 5 if task_type == "pricing" else 3
                results = search_service(current_message, limit=limit)
                
                if results:
                    state["search_results"] = results
                    
                    # –î–ª—è —Ü–µ–Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–Ω–∞—Ö
                    if task_type == "pricing":
                        pricing_info = {"services": [], "exact_prices": {}}
                        for result in results:
                            payload = result.get("payload", {})
                            title = payload.get("title", "")
                            price = payload.get("price", 0)
                            price_str = payload.get("price_str", "")
                            
                            if title:
                                exact_price = price_str if price_str else (f"{price} —Ä—É–±–ª–µ–π" if price > 0 else "—É—Ç–æ—á–Ω–∏—Ç—å —Ü–µ–Ω—É")
                                pricing_info["services"].append({
                                    "title": title,
                                    "price": exact_price,
                                    "score": result.get("score", 0)
                                })
                                pricing_info["exact_prices"][title.lower()] = exact_price
                        
                        state["pricing_info"] = pricing_info
                        log.info(f"üí∞ –ù–∞–π–¥–µ–Ω–æ {len(pricing_info['services'])} —É—Å–ª—É–≥ —Å —Ü–µ–Ω–∞–º–∏")
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    context_parts = []
                    for result in results:
                        payload = result.get("payload", {})
                        title = payload.get("title", "")
                        price_str = payload.get("price_str", "")
                        master = payload.get("master", "")
                        
                        if title:
                            part = f"- {title}"
                            if price_str:
                                part += f": {price_str}"
                            if master:
                                part += f" (–º–∞—Å—Ç–µ—Ä: {master})"
                            context_parts.append(part)
                    
                    state["rag_context"] = "\n".join(context_parts)
                    log.info(f"üîç RAG –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                else:
                    log.info("‚ö†Ô∏è RAG –ø–æ–∏—Å–∫: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            except ImportError:
                log.warning("‚ö†Ô∏è qdrant_helper –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            except Exception as e:
                log.error(f"‚ùå –û—à–∏–±–∫–∞ RAG –ø–æ–∏—Å–∫–∞: {e}")
            
            return state
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ search_rag_node: {e}")
            return state
    
    async def _format_messages_node(self, state: ConversationState) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è LLM"""
        try:
            messages = state.get("messages", [])
            current_message = state.get("current_message", "")
            user_id = state.get("user_id")
            platform = state.get("platform", "telegram")
            
            formatted_messages = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º system prompt
            system_prompt = state.get("system_prompt", "")
            if system_prompt:
                formatted_messages.append({"role": "system", "content": system_prompt})
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
            if messages:
                for msg in messages:
                    if LANGCHAIN_MESSAGES_AVAILABLE and (isinstance(msg, HumanMessage) or isinstance(msg, AIMessage)):
                        role = "user" if isinstance(msg, HumanMessage) else "assistant"
                        content = msg.content if hasattr(msg, 'content') else str(msg)
                        if content:
                            formatted_messages.append({"role": role, "content": content})
                    elif isinstance(msg, dict):
                        role = msg.get("role", "user")
                        content = msg.get("content", msg.get("text", ""))
                        if content:
                            formatted_messages.append({"role": role, "content": content})
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            if current_message:
                formatted_messages.append({"role": "user", "content": current_message})
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                if user_id:
                    try:
                        thread_key = f"{user_id}_{platform}"
                        prev_state = self._thread_states.get(thread_key, {})
                        prev_messages = prev_state.get("messages", [])
                        
                        if LANGCHAIN_MESSAGES_AVAILABLE:
                            prev_messages.append(HumanMessage(content=current_message))
                        else:
                            prev_messages.append({"role": "user", "content": current_message})
                        
                        prev_messages = prev_messages[-self.max_history_messages:]
                        self._thread_states[thread_key] = {"messages": prev_messages}
                    except Exception as e:
                        log.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {e}")
            
            state["formatted_messages"] = formatted_messages
            return state
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return {"error": str(e)}
    
    async def _generate_response_node(self, state: ConversationState) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM"""
        try:
            formatted_messages = state.get("formatted_messages", [])
            current_message = state.get("current_message", "")
            task_type = state.get("task_type", "general")
            rag_context = state.get("rag_context", "")
            pricing_info = state.get("pricing_info", {})
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º system prompt
            system_prompt = state.get("system_prompt", "")
            if not system_prompt:
                system_prompt = """–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π HR –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.
–ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º.
–ü–æ–º–æ–≥–∞–π –∫–ª–∏–µ–Ω—Ç–∞–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –æ–± —É—Å–ª—É–≥–∞—Ö, —Ü–µ–Ω–∞—Ö –∏ –∑–∞–ø–∏—Å–∏.

–ö–†–ò–¢–ò–ß–ù–û –¥–ª—è —Ü–µ–Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–æ—á–Ω—ã–µ —Ü–µ–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π –∏ –ù–ï –æ–∫—Ä—É–≥–ª—è–π —Ü–µ–Ω—ã
- –ï—Å–ª–∏ —Ü–µ–Ω–∞ —É–∫–∞–∑–∞–Ω–∞ –∫–∞–∫ "–æ—Ç X —Ä—É–±–ª–µ–π" - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —ç—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç
- –ï—Å–ª–∏ —Ü–µ–Ω—ã –Ω–µ—Ç –≤ –±–∞–∑–µ - —Å–∫–∞–∂–∏ "—É—Ç–æ—á–Ω–∏—Ç—å —Ü–µ–Ω—É"
"""
            
            if not formatted_messages:
                if current_message:
                    formatted_messages = [{"role": "user", "content": current_message}]
                else:
                    return {"response": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è.", "error": "Empty messages"}
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            prompt_parts = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if rag_context:
                prompt_parts.append(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n{rag_context}")
            
            # –î–ª—è —Ü–µ–Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            if task_type == "pricing" and pricing_info:
                services = pricing_info.get("services", [])
                if services:
                    prices_text = "\n".join([f"- {s['title']}: {s['price']}" for s in services])
                    prompt_parts.append(f"""
–¢–û–ß–ù–´–ï –¶–ï–ù–´ –ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•:
{prices_text}

‚ùå –ó–ê–ü–†–ï–©–ï–ù–û:
- –í—ã–¥—É–º—ã–≤–∞—Ç—å —Ü–µ–Ω—ã
- –û–∫—Ä—É–≥–ª—è—Ç—å —Ü–µ–Ω—ã
- –ò–∑–º–µ–Ω—è—Ç—å —Ñ–æ—Ä–º–∞—Ç —Ü–µ–Ω

‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã
- –§–æ—Ä–º–∞—Ç: "–æ—Ç X —Ä—É–±–ª–µ–π" –∏–ª–∏ "X —Ä—É–±–ª–µ–π"
""")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            prompt_parts.append(f"–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {current_message}")
            
            user_prompt = "\n\n".join(prompt_parts) if prompt_parts else current_message
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM
            try:
                from llm_api import LLMClient
                
                llm_client = LLMClient(
                    primary_provider="openrouter",
                    primary_model="deepseek/deepseek-chat",
                    timeout=30
                )
                
                # –î–ª—è —Ü–µ–Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∏–∑–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
                temperature = 0.3 if task_type == "pricing" else 0.7
                
                response = await llm_client.generate(
                    prompt=user_prompt,
                    system_prompt=system_prompt,
                    temperature=temperature,
                    max_tokens=2048
                )
                
                if response.error:
                    log.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {response.error}")
                    return {"response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.", "error": response.error}
                
                answer = response.content.strip() if response.content else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
                
            except Exception as llm_error:
                log.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞: {llm_error}")
                # Fallback –Ω–∞ openrouter_chat
                try:
                    from app import openrouter_chat
                    messages = [{"role": "user", "content": user_prompt}]
                    answer = await openrouter_chat(messages, use_system_message=True, system_content=system_prompt)
                except Exception as fallback_error:
                    log.error(f"‚ùå Fallback —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {fallback_error}")
                    return {"response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.", "error": str(fallback_error)}
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            user_id = state.get("user_id")
            platform = state.get("platform", "telegram")
            
            if user_id and answer:
                try:
                    thread_key = f"{user_id}_{platform}"
                    prev_state = self._thread_states.get(thread_key, {})
                    prev_messages = prev_state.get("messages", [])
                    
                    if LANGCHAIN_MESSAGES_AVAILABLE:
                        prev_messages.append(AIMessage(content=answer))
                    else:
                        prev_messages.append({"role": "assistant", "content": answer})
                    
                    prev_messages = prev_messages[-self.max_history_messages:]
                    self._thread_states[thread_key] = {"messages": prev_messages}
                except Exception as e:
                    log.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç: {e}")
            
            return {"response": answer}
            
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}", exc_info=True)
            return {"response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.", "error": str(e)}
    
    async def run(
        self,
        message: str,
        message_history: Optional[List[Dict[str, str]]] = None,
        system_prompt: Optional[str] = None,
        task_type: str = "general",
        user_name: Optional[str] = None,
        bot_already_introduced: bool = False,
        needs_user_name: bool = False,
        user_id: Optional[str] = None,
        platform: str = "telegram"
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å workflow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
        
        Args:
            message: –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            message_history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏
            user_name: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            bot_already_introduced: –ë–æ—Ç —É–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª—Å—è?
            needs_user_name: –ù—É–∂–Ω–æ —Å–ø—Ä–æ—Å–∏—Ç—å –∏–º—è?
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—Ç–≤–µ—Ç–æ–º
        """
        log.info(f"üì® LangGraph Conversation Workflow –∑–∞–ø—É—â–µ–Ω, task_type={task_type}")
        
        if not self._initialized:
            if not self.initialize():
                return {
                    "response": "LangGraph –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                    "error": "LangGraph –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                    "status": "error"
                }
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º system prompt –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
            if not system_prompt:
                system_prompt = """–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π HR –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.
–ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º.
–ü–æ–º–æ–≥–∞–π –∫–ª–∏–µ–Ω—Ç–∞–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –æ–± —É—Å–ª—É–≥–∞—Ö, —Ü–µ–Ω–∞—Ö –∏ –∑–∞–ø–∏—Å–∏.

–ö–†–ò–¢–ò–ß–ù–û:
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–æ—á–Ω—ã–µ —Ü–µ–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π —Ü–µ–Ω—ã
- –ï—Å–ª–∏ —Ü–µ–Ω—ã –Ω–µ—Ç - —Å–∫–∞–∂–∏ "—É—Ç–æ—á–Ω–∏—Ç—å —Ü–µ–Ω—É"
"""
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            initial_state: ConversationState = {
                "messages": message_history or [],
                "current_message": message,
                "system_prompt": system_prompt,
                "task_type": task_type,
                "response": None,
                "error": None,
                "user_name": user_name,
                "user_id": user_id,
                "platform": platform,
                "bot_already_introduced": bot_already_introduced,
                "needs_user_name": needs_user_name,
                "rag_context": None,
                "search_results": None,
                "pricing_info": None
            }
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º workflow
            result = await self.graph.ainvoke(initial_state)
            
            response = result.get("response", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç")
            log.info(f"‚úÖ LangGraph –∑–∞–≤–µ—Ä—à–∏–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, length={len(response) if response else 0}")
            
            return {
                "response": response,
                "error": result.get("error"),
                "status": "success" if not result.get("error") else "error",
                "task_type": result.get("task_type", task_type),
                "pricing_info": result.get("pricing_info"),
                "search_results": result.get("search_results")
            }
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ LangGraph workflow: {e}", exc_info=True)
            return {
                "response": f"–û—à–∏–±–∫–∞: {str(e)}",
                "error": str(e),
                "status": "error"
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä workflow
_conversation_workflow: Optional[LangGraphConversationWorkflow] = None


def get_conversation_workflow(max_history_messages: int = 50) -> LangGraphConversationWorkflow:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä LangGraph Conversation Workflow"""
    global _conversation_workflow
    if _conversation_workflow is None:
        _conversation_workflow = LangGraphConversationWorkflow(max_history_messages=max_history_messages)
        _conversation_workflow.initialize()
    return _conversation_workflow


async def query_with_conversation_workflow(
    message: str,
    user_id: str = None,
    platform: str = "telegram",
    message_history: List[Dict[str, str]] = None
) -> Dict[str, Any]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ LangGraph Conversation Workflow
    
    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
        message_history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    workflow = get_conversation_workflow()
    return await workflow.run(
        message=message,
        user_id=user_id,
        platform=platform,
        message_history=message_history
    )
